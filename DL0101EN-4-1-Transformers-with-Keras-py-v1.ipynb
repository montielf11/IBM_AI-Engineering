{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0101EN-SkillsNetwork/images/IDSN-logo.png\" width=\"400\"> </a>\n",
    "\n",
    "# Transformers with Keras\n",
    "\n",
    "Estimated time needed **45** mins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will learn how to use the Keras library to build a transformer using a sequence-to-sequence architecture with self-attention for translation. We will train the model using a sample dataset and then use this model for English to Spanish translation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives for this Notebook    \n",
    "* How to use the Keras library to build transformers model\n",
    "* Train the transformer model using a given dataset\n",
    "* Use the trained transformer model to translate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 4>\n",
    "1. <a href=\"#Import-Keras-and-Packages\">Import Keras and Packages</a><br>\n",
    "2. <a href=\"#Step-1:-Data-Preparation\">Step 1: Data Preparation</a><br>\n",
    "3. <a href=\"#Step-2:-Self-Attention-Layer\">Step 2: Self-Attention Layer</a><br>\n",
    "4. <a href=\"#Step-3:-Model-Architecture\">Step 3: Model Architecture</a><br>\n",
    "5. <a href=\"#Step-4:-Training-the-Model\">Step 4: Training the Model</a><br>\n",
    "6. <a href=\"#Step-5:-Plotting-the-training-loss\">Step 5: Plotting the training loss</a><br>\n",
    "\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the keras libraries and the packages that we would need to build a neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.17.1 in /opt/conda/lib/python3.12/site-packages (2.17.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (1.74.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.17.1) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow==2.17.1) (14.1.0)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow==2.17.1) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow==2.17.1) (0.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.1) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.1) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.1) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow==2.17.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow==2.17.1) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow==2.17.1) (0.1.2)\n",
      "Requirement already satisfied: matplotlib==3.9.2 in /opt/conda/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.9.2) (1.17.0)\n",
      "==== All required libraries are installed =====\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.17.1\n",
    "!pip install matplotlib==3.9.2\n",
    "\n",
    "print(\"==== All required libraries are installed =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppress the tensorflow warning messages\n",
    "We use the following code to  suppress the warning messages due to use of CPU architechture for tensoflow.\n",
    "\n",
    "You may want to **comment out** these lines if you are using the GPU architechture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To use Keras, you will also need to install a backend framework – such as TensorFlow.\n",
    "\n",
    "If you install TensorFlow 2.16 or above, it will install Keras by default.\n",
    "\n",
    "We are using the CPU version of tensorflow since we are dealing with smaller datasets. \n",
    "You may install the GPU version of tensorflow on your machine to accelarate the processing of larger datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 20:51:43.645646: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-29 20:51:43.667593: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-29 20:51:43.675161: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.layers import Layer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Preparation\n",
    "We start by define the sentences and text for translation training\n",
    "Sentence Pairs: Defines a small dataset of English-Spanish sentence pairs.\n",
    "Target Sequences:\n",
    "Prepends \"startseq\" and appends \"endseq\" to each target sentence for the decoder to learn when to start and stop translating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample parallel sentences (English -> Spanish)\n",
    "input_texts = [\n",
    "    \"Hello.\", \"How are you?\", \"I am learning machine translation.\", \"What is your name?\", \"I love programming.\"\n",
    "]\n",
    "target_texts = [\n",
    "    \"Hola.\", \"¿Cómo estás?\", \"Estoy aprendiendo traducción automática.\", \"¿Cuál es tu nombre?\", \"Me encanta programar.\"\n",
    "]\n",
    "\n",
    "target_texts = [\"startseq \" + x + \" endseq\" for x in target_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, we convert the text from the sentences to tokens and create a vocabulary\n",
    "Tokenization: Uses Tokenizer to convert words into numerical sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "input_tokenizer = Tokenizer()\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
    "\n",
    "output_tokenizer = Tokenizer()\n",
    "output_tokenizer.fit_on_texts(target_texts)\n",
    "output_sequences = output_tokenizer.texts_to_sequences(target_texts)\n",
    "\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "output_vocab_size = len(output_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now pad the corresponding sentences\n",
    "Padding: Ensures all sequences have the same length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "max_input_length = max([len(seq) for seq in input_sequences])\n",
    "max_output_length = max([len(seq) for seq in output_sequences])\n",
    "\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_input_length, padding='post')\n",
    "output_sequences = pad_sequences(output_sequences, maxlen=max_output_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the target data for training\n",
    "decoder_input_data = output_sequences[:, :-1]\n",
    "decoder_output_data = output_sequences[:, 1:]\n",
    "\n",
    "# Convert to one-hot\n",
    "decoder_output_data = np.array([np.eye(output_vocab_size)[seq] for seq in decoder_output_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Self-Attention Layer\n",
    "Self-attention is a mechanism that allows a model to **focus on relevant parts of the input sequence** while processing each word. This is particularly useful in:\n",
    "1) Machine Translation (e.g., aligning words correctly)\n",
    "2) Text Summarization\n",
    "3) Speech Recognition\n",
    "4) Image Processing (Vision Transformers)\n",
    "In this implementation, self-attention is used for text based sequence-to-sequence modeling.\n",
    "\n",
    "\n",
    "Self-Attention works for a given an input sequence by computing a weighted representation of all words for each position. It does so using three key components:\n",
    "\n",
    "1. Query **(Q)**, Key **(K)**, and Value **(V)** Matrices\n",
    "For each word (token) in a sequence:\n",
    "\n",
    "Query (Q): What this word is looking for.\n",
    "Key (K): What this word represents.\n",
    "Value (V): The actual information in the word.\n",
    "\n",
    "2. Compute **Attention Scores**\n",
    "Next, we **calculate the similarity between each query and key** using dot-product attention:\n",
    "Each word in a sequence attends to every other word based on these scores.\n",
    "\n",
    "3. Apply **Scaling & Softmax**\n",
    "Since dot-product values can be large, we scale them. \n",
    "Next, Applying softmax converts scores into attention weights:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Attention class\n",
    "In this implementation of self-attention layer:\n",
    "1. We first initialize the weights in the **build** method, where:\n",
    "    1. **self.Wq**, **self.Wk**, **self.Wv** are the trainable weight matrices.\n",
    "    2. Their **shape is (feature_dim, feature_dim)**, meaning they transform input features into Q, K, and V representations.\n",
    "2. Applying Attention using **call** method. The **call()** method:\n",
    "   1. Computes **Q, K, V** by multiplying inputs (encoder/decoder output) with their respective weight matrices.\n",
    "   2. Computes **dot-product attention scores** using K.batch_dot(q, k, axes=[2, 2]), resulting in a (batch_size, seq_len, seq_len) matrix.\n",
    "   3. **Scales** the scores to avoid large values.\n",
    "   4. Applies **softmax** to normalize the attention scores.\n",
    "   5. **Multiplies attention weights with V** to get the final output.\n",
    "3. The **compute_output_shape** method defines the shape of the output tensor after the layer processes an input.\n",
    "    1. The output shape of the Self-Attention layer **remains the same** as the input shape.\n",
    "    2. The attention mechanism **transforms** the input but does not change its dimensions.4\n",
    "    3. If the attention layer changed the shape, you would modify compute_output_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Model Architecture\n",
    "The model follows an Encoder-Decoder structure:\n",
    "\n",
    "### Encoder:\n",
    "1) Takes input sentences (padded and tokenized).\n",
    "2) Uses an Embedding layer (word representations) + LSTM (to process sequences).\n",
    "    1. The LSTMs are used as the **help process variable-length input sentences** and generate meaningful translations.\n",
    "4) Outputs context vectors (hidden & cell states).\n",
    "\n",
    "### Attention Layer\n",
    "1) Applied to both the encoder and decoder outputs.\n",
    "2) Helps the decoder focus on relevant words during translation.\n",
    "\n",
    "### Decoder\n",
    "1) Receives target sequences (shifted one step ahead).\n",
    "2) Uses an LSTM with encoder states as initial states.\n",
    "3) Applies self-attention for better learning.\n",
    "4) Uses a Dense layer (Softmax) to predict the next word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,608</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,369</span> │ self_attention_1… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,352\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │    \u001b[38;5;34m196,608\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mSelfAttention\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m)     │      \u001b[38;5;34m4,369\u001b[0m │ self_attention_1… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,260,049</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,260,049\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,260,049</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,260,049\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Attention Mechanism\n",
    "attention_layer = SelfAttention()(encoder_outputs)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_attention = SelfAttention()(decoder_outputs)  # Apply attention\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_attention)\n",
    "\n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Training the Model\n",
    "Uses categorical_crossentropy as the loss function since output words are one-hot encoded.\n",
    "Trains using Adam optimizer for 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.0400 - loss: 2.8320\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.3200 - loss: 2.7962\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.3200 - loss: 2.7537\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.2800 - loss: 2.6942\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.2800 - loss: 2.6077\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.2800 - loss: 2.4884\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.2400 - loss: 2.3604\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.2400 - loss: 2.3514\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.2800 - loss: 2.3675\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.3200 - loss: 2.3002\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.3200 - loss: 2.2490\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.3200 - loss: 2.2221\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.3200 - loss: 2.2004\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.3200 - loss: 2.1702\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.3200 - loss: 2.1265\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.3200 - loss: 2.0739\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.3200 - loss: 2.0256\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.3200 - loss: 1.9908\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.3200 - loss: 1.9595\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.3200 - loss: 1.9138\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.3200 - loss: 1.8553\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.3200 - loss: 1.7985\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.3200 - loss: 1.7515\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.3200 - loss: 1.7053\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.3200 - loss: 1.6464\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.3200 - loss: 1.5884\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.3200 - loss: 1.5640\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.3200 - loss: 1.5517\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.2800 - loss: 1.5142\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.3200 - loss: 1.5052\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.2800 - loss: 1.4937\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.3200 - loss: 1.4807\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.3200 - loss: 1.4724\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.3200 - loss: 1.4523\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.3200 - loss: 1.4583\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.3200 - loss: 1.4345\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.3600 - loss: 1.4259\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.3200 - loss: 1.4221\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.3600 - loss: 1.4026\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.3600 - loss: 1.3989\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.3600 - loss: 1.3792\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.3200 - loss: 1.3532\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.4000 - loss: 1.3370\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.3600 - loss: 1.2961\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.3600 - loss: 1.2634\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.5200 - loss: 1.2235\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.5200 - loss: 1.1835\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.4800 - loss: 1.1448\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.5200 - loss: 1.1036\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.5200 - loss: 1.0608\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5200 - loss: 1.0228\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.6800 - loss: 0.9877\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.5200 - loss: 0.9790\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.4800 - loss: 1.0250\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.6000 - loss: 0.9475\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.6000 - loss: 0.9925\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5600 - loss: 0.9381\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.5600 - loss: 0.9508\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.6400 - loss: 0.8472\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.6000 - loss: 0.8539\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.5600 - loss: 0.8683\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.6400 - loss: 0.9668\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.6000 - loss: 0.9201\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.6000 - loss: 0.8200\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.6800 - loss: 0.8234\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.6800 - loss: 0.8574\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.6400 - loss: 0.7856\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.7600 - loss: 0.7449\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7600 - loss: 0.6941\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.7600 - loss: 0.7200\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7600 - loss: 0.6967\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.8400 - loss: 0.6160\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.8000 - loss: 0.6092\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7600 - loss: 0.6112\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.8400 - loss: 0.5991\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.8400 - loss: 0.5442\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.8400 - loss: 0.4972\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7600 - loss: 0.5041\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8000 - loss: 0.4798\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8800 - loss: 0.4414\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9200 - loss: 0.4217\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9200 - loss: 0.4119\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.9200 - loss: 0.4029\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.9200 - loss: 0.3749\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.9200 - loss: 0.3509\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.9200 - loss: 0.3386\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9200 - loss: 0.3279\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9200 - loss: 0.3115\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.9200 - loss: 0.2950\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.9200 - loss: 0.2840\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9200 - loss: 0.2774\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.9600 - loss: 0.2677\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9600 - loss: 0.2527\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9600 - loss: 0.2408\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.9600 - loss: 0.2364\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.9600 - loss: 0.2393\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8800 - loss: 0.2688\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.9200 - loss: 0.2109\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9600 - loss: 0.2299\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.9600 - loss: 0.2028\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train the Model\n",
    "history_glorot_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Plotting the training loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awesome, now you have succesfully trained a transformers model.\n",
    "### Now let's try some practice excercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice excercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practice exercise, let's train the model using \"he_uniform\" initializer instead of \"glorot_uniform\". Then, compare the training loss between model using \"glorot_uniform\" vs \"he_uniform\" initializers by plotting them using matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_7    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,608</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,369</span> │ self_attention_7… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,352\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_7    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │    \u001b[38;5;34m196,608\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mSelfAttention\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m)     │      \u001b[38;5;34m4,369\u001b[0m │ self_attention_7… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,260,049</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,260,049\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,260,049</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,260,049\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 2.8346\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.2400 - loss: 2.7857\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.2400 - loss: 2.7312\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.2400 - loss: 2.6603\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.2400 - loss: 2.5641\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.2400 - loss: 2.4422\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.2400 - loss: 2.3378\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.2400 - loss: 2.3554\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.2800 - loss: 2.3165\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.3200 - loss: 2.2322\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.3200 - loss: 2.1838\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.3200 - loss: 2.1594\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.2000 - loss: 2.1288\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.3200 - loss: 2.0802\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.3200 - loss: 2.0135\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.3200 - loss: 1.9374\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.3200 - loss: 1.8693\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.3200 - loss: 1.8243\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.3200 - loss: 1.7912\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.3200 - loss: 1.7452\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.3200 - loss: 1.6907\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.3200 - loss: 1.6455\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.3200 - loss: 1.6104\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.3200 - loss: 1.5757\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.3200 - loss: 1.5331\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.3200 - loss: 1.5060\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.3200 - loss: 1.5106\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.2800 - loss: 1.4913\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.3200 - loss: 1.4537\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.3200 - loss: 1.4567\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.3200 - loss: 1.4558\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.3200 - loss: 1.4337\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.3200 - loss: 1.4238\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.3200 - loss: 1.4171\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.3200 - loss: 1.4044\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.3600 - loss: 1.3871\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.3600 - loss: 1.3619\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.3200 - loss: 1.3528\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.3200 - loss: 1.3204\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.3600 - loss: 1.2926\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.3600 - loss: 1.2695\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.3600 - loss: 1.2375\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.4400 - loss: 1.1986\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.4800 - loss: 1.1625\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.4400 - loss: 1.1292\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.4400 - loss: 1.1029\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.4800 - loss: 1.0842\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.5200 - loss: 1.0516\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.6000 - loss: 1.0269\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.6000 - loss: 1.0081\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.5600 - loss: 0.9798\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.6000 - loss: 0.9588\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.5200 - loss: 1.0200\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.5200 - loss: 0.9411\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.5600 - loss: 0.9320\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.6400 - loss: 0.9075\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.6000 - loss: 0.8844\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.5600 - loss: 0.9146\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.6000 - loss: 0.8920\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7200 - loss: 0.8609\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.6800 - loss: 0.8944\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.6000 - loss: 0.8803\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.6000 - loss: 0.8242\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.6000 - loss: 0.8429\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.7600 - loss: 0.7556\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.6400 - loss: 0.8011\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.6800 - loss: 0.7358\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.6800 - loss: 0.7453\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.7600 - loss: 0.7103\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.7200 - loss: 0.6907\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.6800 - loss: 0.7025\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8400 - loss: 0.6643\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.7200 - loss: 0.6741\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7200 - loss: 0.6465\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7600 - loss: 0.6182\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.8000 - loss: 0.5916\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8000 - loss: 0.5749\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8400 - loss: 0.5554\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8000 - loss: 0.5343\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8400 - loss: 0.5208\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8400 - loss: 0.5073\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.8800 - loss: 0.4857\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.8400 - loss: 0.4653\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.8400 - loss: 0.4487\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8400 - loss: 0.4313\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8800 - loss: 0.4101\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.9200 - loss: 0.3904\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.9200 - loss: 0.3702\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.9200 - loss: 0.3484\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.9200 - loss: 0.3317\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9200 - loss: 0.3122\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.9200 - loss: 0.2915\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9200 - loss: 0.2725\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9600 - loss: 0.2539\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.2356\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.9600 - loss: 0.2198\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9600 - loss: 0.2061\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.9600 - loss: 0.1922\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.1782\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.1654\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Write your answer here\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Attention Mechanism\n",
    "attention_layer = SelfAttention()(encoder_outputs)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_attention = SelfAttention()(decoder_outputs)  # Apply attention\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_attention)\n",
    "\n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model.summary()\n",
    "##Train the Model\n",
    "he_uniform_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "##Plot the model's loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'])\n",
    "plt.plot(he_uniform_adam.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "\n",
    "#Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    \n",
    "#Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "#Attention Mechanism\n",
    "attention_layer = SelfAttention()(encoder_outputs)\n",
    "\n",
    "#Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_attention = SelfAttention()(decoder_outputs)  # Apply attention\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_attention)\n",
    "\n",
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_he = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"glorot_uniform\", color='red')\n",
    "plt.plot(history_he.history['loss'], label=\"he_uniform\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice excercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practice exercise, try to use adaptive gradient optimizer instead of adam. Then, plot and compare the results between adam and adaptive gradient optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.1461\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.1461\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.1460\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.1459\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.1459\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 1.0000 - loss: 0.1458\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.1458\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.1457\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.1457\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.1456\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 1.0000 - loss: 0.1456\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.1455\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.1455\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.1454\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.1454\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.1453\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.1452\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.1452\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.1451\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.1451\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.1450\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.1450\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.1449\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.1449\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 1.0000 - loss: 0.1448\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.1448\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.1447\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.1447\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.1446\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.1446\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.1445\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 1.0000 - loss: 0.1445\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.1444\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.1443\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.1443\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.1442\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.1442\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 1.0000 - loss: 0.1441\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 0.1441\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 0.1440\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.1440\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 1.0000 - loss: 0.1439\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.1439\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.1438\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.1438\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.1437\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.1437\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.1436\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.1436\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.1435\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.1435\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.1434\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.1434\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.1433\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.1433\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.1432\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.1432\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.1431\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.1431\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.1430\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.1430\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.1429\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.1429\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.1428\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.1428\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.1427\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.1427\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.1426\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.1426\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.1425\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.1425\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.1424\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.1424\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.1423\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.1423\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.1422\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.1422\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.1421\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.1421\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.1420\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.1420\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.1419\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.1419\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.1418\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 0.1418\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.1417\n",
      "Epoch 87/100\n"
     ]
    }
   ],
   "source": [
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_adagrad = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"adam\", color='red')\n",
    "plt.plot(history_adagrad.history['loss'], label=\"adagrad\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_adagrad = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"adam\", color='red')\n",
    "plt.plot(history_adagrad.history['loss'], label=\"adagrad\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by [Aman Aggarwal](https://www.linkedin.com/in/aggarwal-aman/). I hope you found this lab interesting and educational. Feel free to contact me if you have any questions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2024-11-20  | 1.0  | Aman  |  Created the lab |\n",
    "<hr>\n",
    "-->\n",
    "## <h3 align=\"center\"> © IBM Corporation. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "89fa9a3db18ab099ea8b241e966f29a2f658cfbd6a742128f10daea40c67df82"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
